{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 64)     36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_4[0][0]                   \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 9, 9, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 64)     0           conv2d_6[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 64)     36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          16640       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           2570        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ResNet on CIFER10 dataset\n",
    "inputs = keras.Input(shape=(32,32,3),name='img')\n",
    "x = Conv2D(32,3,activation='relu')(inputs)\n",
    "x = Conv2D(64,3,activation='relu')(x)\n",
    "block_1_output = layers.MaxPool2D(3)(x)\n",
    "\n",
    "x = Conv2D(64,3,activation='relu',padding='same')(block_1_output)\n",
    "x = Conv2D(64,3,activation='relu',padding='same')(x)\n",
    "block_2_output = layers.add([x,block_1_output])\n",
    "\n",
    "x = Conv2D(64,3,activation='relu',padding='same')(block_2_output)\n",
    "x = Conv2D(64,3,activation='relu',padding='same')(x)\n",
    "block_3_output = layers.add([x,block_2_output])\n",
    "\n",
    "x = Conv2D(64,3,activation='relu',padding='same')(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(256,activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = Dense(10)(x)\n",
    "model = keras.Model(inputs,outputs,name='toy_resnet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 23.7220 - acc: 0.1690 - val_loss: 2.3045 - val_acc: 0.0920\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2971 - acc: 0.1140 - val_loss: 2.2827 - val_acc: 0.1240\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2798 - acc: 0.1130 - val_loss: 2.3054 - val_acc: 0.1150\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3050 - acc: 0.1120 - val_loss: 2.3033 - val_acc: 0.1120\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3066 - acc: 0.0850 - val_loss: 2.3023 - val_acc: 0.1030\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3026 - acc: 0.0860 - val_loss: 2.3019 - val_acc: 0.1120\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3017 - acc: 0.1130 - val_loss: 2.3021 - val_acc: 0.1140\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3025 - acc: 0.1050 - val_loss: 2.3030 - val_acc: 0.1140\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3019 - acc: 0.1190 - val_loss: 2.3028 - val_acc: 0.0890\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3010 - acc: 0.1050 - val_loss: 2.3025 - val_acc: 0.0890\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3013 - acc: 0.1080 - val_loss: 2.3026 - val_acc: 0.0890\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3019 - acc: 0.1120 - val_loss: 2.3028 - val_acc: 0.0890\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3002 - acc: 0.1110 - val_loss: 2.3025 - val_acc: 0.0890\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3007 - acc: 0.1110 - val_loss: 2.3029 - val_acc: 0.0890\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3004 - acc: 0.1150 - val_loss: 2.3031 - val_acc: 0.0890\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3010 - acc: 0.1190 - val_loss: 2.3032 - val_acc: 0.0890\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3004 - acc: 0.1120 - val_loss: 2.3031 - val_acc: 0.0890\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3014 - acc: 0.1150 - val_loss: 2.3031 - val_acc: 0.0890\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3000 - acc: 0.1070 - val_loss: 2.3029 - val_acc: 0.0890\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2998 - acc: 0.1140 - val_loss: 2.3024 - val_acc: 0.0890\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2983 - acc: 0.1120 - val_loss: 2.3029 - val_acc: 0.0890\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2926 - acc: 0.1140 - val_loss: 2.3742 - val_acc: 0.0950\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3188 - acc: 0.1280 - val_loss: 2.3034 - val_acc: 0.1120\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3048 - acc: 0.1130 - val_loss: 2.3085 - val_acc: 0.0990\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3045 - acc: 0.1040 - val_loss: 2.3017 - val_acc: 0.1120\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3034 - acc: 0.1070 - val_loss: 2.3026 - val_acc: 0.1120\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.3002 - acc: 0.1120 - val_loss: 2.3020 - val_acc: 0.1120\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.3008 - acc: 0.1140 - val_loss: 2.3025 - val_acc: 0.0890\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2996 - acc: 0.1100 - val_loss: 2.3020 - val_acc: 0.0890\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2993 - acc: 0.1160 - val_loss: 2.2951 - val_acc: 0.1370\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2919 - acc: 0.1380 - val_loss: 2.2924 - val_acc: 0.0940\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2862 - acc: 0.1460 - val_loss: 2.2856 - val_acc: 0.1190\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2715 - acc: 0.1460 - val_loss: 2.2541 - val_acc: 0.1360\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2628 - acc: 0.1370 - val_loss: 2.2526 - val_acc: 0.1380\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2527 - acc: 0.1540 - val_loss: 2.2511 - val_acc: 0.1350\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2581 - acc: 0.1450 - val_loss: 2.2274 - val_acc: 0.1540\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2498 - acc: 0.1540 - val_loss: 2.2106 - val_acc: 0.1730\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.2069 - acc: 0.1790 - val_loss: 2.2098 - val_acc: 0.1420\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1971 - acc: 0.1600 - val_loss: 2.1645 - val_acc: 0.1740\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1703 - acc: 0.2080 - val_loss: 2.1271 - val_acc: 0.2080\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1510 - acc: 0.1840 - val_loss: 2.1224 - val_acc: 0.1890\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1349 - acc: 0.1940 - val_loss: 2.1050 - val_acc: 0.1980\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1367 - acc: 0.1900 - val_loss: 2.1066 - val_acc: 0.2030\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.1140 - acc: 0.2110 - val_loss: 2.1119 - val_acc: 0.2030\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1170 - acc: 0.2020 - val_loss: 2.0992 - val_acc: 0.1980\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1176 - acc: 0.2150 - val_loss: 2.0870 - val_acc: 0.2130\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1173 - acc: 0.2100 - val_loss: 2.0887 - val_acc: 0.2110\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0833 - acc: 0.2060 - val_loss: 2.0947 - val_acc: 0.2040\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0936 - acc: 0.2100 - val_loss: 2.1005 - val_acc: 0.2080\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0876 - acc: 0.2140 - val_loss: 2.0776 - val_acc: 0.2090\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "(xtrain,ytrain),(xtest,ytest) = keras.datasets.cifar10.load_data()\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "xtrain = xtrain/255\n",
    "xtest = xtest/255\n",
    "ytrain = keras.utils.to_categorical(ytrain,10)\n",
    "ytest = keras.utils.to_categorical(ytest,10)\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-2), loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['acc'])\n",
    "history = model.fit(xtrain[:1000],ytrain[:1000],epochs=50,validation_data=(xtest[:1000],ytest[:1000]),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('resnet_model')\n",
    "\n",
    "# load the model\n",
    "model = keras.models.load_model('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25906688888>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
